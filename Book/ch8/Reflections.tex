\documentclass[10pt, english]{article}
\usepackage[T1]{fontenc}
\usepackage{babel}
\usepackage{amsfonts} 
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{titlesec}
\usepackage{changepage}
\usepackage{setspace}
\usepackage[margin=0.875in]{geometry}
\usepackage{multicol}
\usepackage{xcolor}

\begin{document}
\title{Reflections on Chapter 7}
\date{}
\author{}

\maketitle


\section*{General Thoughts}
This is a chapter I've been looking forward to. Tree based models haven't come up in any of the courses I've taken, despite their efficiency, and popularity in applied data science. It's very nice to finally have trees, random forests and gradient boosting in my toolbox from here on out.
The section on Neural networks is pretty shallow, and given that I've spent a lot of time on Neural networks already I didn't pick up anything new from it, but the chapter does gather a number of convergence properties nicely for various cases, so it'll be a good reference if I need a source for that or want to quickly check in the future.


\section*{Space for future reading}
It could be interesting to dig into the docs of some of the python libraries mentioned in this chapter, like xgboost or the sklearn tree implentation, just to get a bit of an idea of what kinds of tricks are being used in those libraries, and be better prepared to apply these tools in the future.

\end{document}